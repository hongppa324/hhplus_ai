4주차 멘토링

few shot prompting을 가장 먼저 시도해보긴 함
보편적인 task에서는 few shot, one shot이 작용하지 않음

정답지 부분의 one shot을 주면 다른 유형의 task에서는 

gpt 4.1과 cookbook 발행
google도 gemini cookbook 나옴 (저번 주)

googling 하면 prompt framework : costar
https://brunch.co.kr/@bobbyryu/121


아직은 진행해보지 않았지만, 최근 몇 개년 수능 문제를 예시로 주고 해볼까 했는데 그거는 few-shot prompting이 아닌가요?? few-shot이 5개 ~ 60개라고 발제 때 들었던 거 같아서요.

최근 몇 개년의 수능 문제 괜찮을 것 같은데 -> 많은 유형을 담을 수 있는 prompt를 주는 것

마지막에 감정에 호소하는 것을


- CoT가 성능이 좋아지긴한데 번호만 출력하는거 대비 생각을 출력하게 하면 latency가 너무 늘어나는거 같기도 하네요.. 이런 실험할땐 항상 사용해보는데 실제 상품화에서 많이 쓰이나요??

CoT에서 latency라기 보다는 입력되는 text 대비 만들어내는 답변이 얼마나 오래 걸리느냐
CoT로 안 쪽에 프롬프팅이 들어가 있음

답변의 양이 많아지면서 latency가 더 오래 걸리는 문제가 생길 수도 있음
답변의 양을 줄이는 prompt를 추가


- instruction prompt 를 작성할때 너무 길면 더 안좋을까요?
instruction은 가이드를 주기위함 : step으로 나눠서 주기도 함

- 그리고 각 에이전트마다 단일 명령 프롬프팅이 더 잘 알아듣는거 같은데 다중 작업으로 프롬프팅을 하면 알아듣지 못할지 궁금합니다

agent AI를 만들었을 때, task를 각 agent 별로 쪼개서 speciality를 줌
마지막에 judge agent에게 추론해라

- image data가 들어오면 classification하는 문제
agent 방식으로 나눔
image를 크게 대분류로 나누는 agent
대분류 안에 각각의 class 마다 agent (gpt-4o)를 만듦
최종적으로 judge AI (gpt 4)가 추론

비동기처리로 latency가 너무 길어져서 최종 답변이 늦어지는 우려가 있음
30초 ~ 1분 내외에서 답변을 얻어도 되는 상황이라 괜찮음

- 너무 system prompt에 명령이 너무 길면 벌써 토큰을 많이 잡아 먹어서 대화하다보면 기존 대화를 잊어버릴 가능성이 많을까요
앞이나 뒤에 context가 날라갈 수 있음
context length를 잘 계산해서 prompting을 하는 것도 중요함

- multi-turn 구조에서 만들 때
기존의 대화 내용을 요약해서 메모리에 올려놓고 하는 경우도 있음
그 다음 turn에 제공하고 함

- 이미지도 RAG로 처리해서 하는 중

심화 과제 앞에는 cursor가 
뒤에는 streamlit으로 

뒤에는 langchain

n8n으로 RAG ==> LLM만 넣으면 됨

cursor, claude, cline, 