{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff92c6a1-b4f8-4846-bcd9-da0f2bd3fe71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.12/site-packages (4.66.5)\n",
      "Requirement already satisfied: boto3 in /opt/anaconda3/lib/python3.12/site-packages (1.37.28)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (2.32.3)\n",
      "Requirement already satisfied: regex in /opt/anaconda3/lib/python3.12/site-packages (2024.11.6)\n",
      "Requirement already satisfied: sentencepiece in /opt/anaconda3/lib/python3.12/site-packages (0.2.0)\n",
      "Requirement already satisfied: sacremoses in /opt/anaconda3/lib/python3.12/site-packages (0.1.1)\n",
      "Requirement already satisfied: datasets in /opt/anaconda3/lib/python3.12/site-packages (3.5.0)\n",
      "Requirement already satisfied: botocore<1.38.0,>=1.37.28 in /opt/anaconda3/lib/python3.12/site-packages (from boto3) (1.37.28)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/anaconda3/lib/python3.12/site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.12.0,>=0.11.0 in /opt/anaconda3/lib/python3.12/site-packages (from boto3) (0.11.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests) (2025.1.31)\n",
      "Requirement already satisfied: click in /opt/anaconda3/lib/python3.12/site-packages (from sacremoses) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/anaconda3/lib/python3.12/site-packages (from sacremoses) (1.4.2)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: xxhash in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.6.1)\n",
      "Requirement already satisfied: aiohttp in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (3.10.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (0.29.3)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/anaconda3/lib/python3.12/site-packages (from botocore<1.38.0,>=1.37.28->boto3) (2.9.0.post0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (1.11.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.24.0->datasets) (4.11.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.38.0,>=1.37.28->boto3) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm boto3 requests regex sentencepiece sacremoses datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32093214-05bb-4fc6-86c1-c0ab4ae184f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertTokenizer(name_or_path='distilbert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True, added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torchinfo import summary\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import transformers\n",
    "from transformers import DistilBertTokenizer, DistilBertConfig, DistilBertModel\n",
    "\n",
    "# DistilBERTTokenizer 가져오기 (pretrained)\n",
    "# 이 tokenizer는 문장을 토큰화해서 모델이 이해할 수 있는 input_ids로 변환해줌\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f83caef-9e43-4ffd-8798-710e04eea5ad",
   "metadata": {},
   "source": [
    "## special token\n",
    "- [PAD] : 길이를 맞춰주기위해 넣어주는 토큰\n",
    "- [UNK] : Tokenizer에 없는 단어를 대체하는 토큰\n",
    "- [CLS] : 문장의 시작을 구분하는 토큰\n",
    "- [SEP] : 문장의 끝을 구분하는 토큰\n",
    "- [MASK] : 특정 토큰을 가리는 토큰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "915da3e4-c590-4901-8e58-0bb021c63c29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d25751c728c4c6d8a8d171317797fbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/8.07k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74cab7a249e440968222c7a9b30c8561",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/18.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8483684de4a74604bf37e416f697fa3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/1.23M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af824209c4a34a7786e3f09190df2548",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/120000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a64512a21584306b44397cc1b6bed32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/7600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 뉴스 기사 데이터셋의 5%만 가져오기\n",
    "train_ds = load_dataset(\"fancyzhx/ag_news\", split=\"train[:5%]\")\n",
    "test_ds = load_dataset(\"fancyzhx/ag_news\", split=\"test[:5%]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "687bb3c2-7466-4a82-be0e-9c8a4f795f71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data length: 6000\n",
      "train label length: 6000\n",
      "train sample: Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\band of ultra-cynics, are seeing green again. | 2\n",
      "test data length: 380\n",
      "test label length: 380\n",
      "test sample: Fears for T N pension after talks Unions representing workers at Turner   Newall say they are 'disappointed' after talks with stricken parent firm Federal Mogul. | 2\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋 형태 확인하기\n",
    "\n",
    "train_text = train_ds['text']\n",
    "train_label = train_ds['label']\n",
    "\n",
    "test_text = test_ds['text']\n",
    "test_label = test_ds['label']\n",
    "\n",
    "print(f'train data length: {len(train_text)}')\n",
    "print(f'train label length: {len(train_label)}')\n",
    "print(f'train sample: {train_text[0]} | {train_label[0]}')\n",
    "\n",
    "print(f'test data length: {len(test_text)}')\n",
    "print(f'test label length: {len(test_label)}')\n",
    "print(f'test sample: {test_text[0]} | {test_label[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7194af-6ed1-479a-8d97-678f0bc8a19d",
   "metadata": {},
   "source": [
    "# huggingface : dataset 정보\n",
    "* text: a string feature => 기사  \n",
    "* label: a classification label (4개로 분류됨)\n",
    " : World (0), Sports (1), Business (2), Sci/Tech (3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8f331c3b-1911-4114-aae3-ae788651948e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터를 배치로 묶는 함수 정의\n",
    "def collate_fn(batch):\n",
    "    max_len = 400  # 입력 문장의 최대 길이 설정\n",
    "    texts, labels = [], []  # 입력 문장들과 라벨들을 저장할 리스트\n",
    "\n",
    "    # 배치 내 각 샘플에 대해 text와 label 추출\n",
    "    for row in batch:\n",
    "        labels.append(row['label'])\n",
    "        texts.append(row['text'])\n",
    "\n",
    "    # tokenizer로 텍스트를 토큰화 : truncation=False로 수정\n",
    "    texts = torch.LongTensor(\n",
    "        tokenizer(texts, padding=True, truncation=False, max_length=max_len).input_ids\n",
    "    )\n",
    "\n",
    "    # 라벨 리스트를 LongTensor로 변환\n",
    "    labels = torch.LongTensor(labels)\n",
    "\n",
    "    # 모델 학습에 필요한 입력 (토큰화된 문장들)과 정답 라벨 반환\n",
    "    return texts, labels\n",
    "\n",
    "# 학습용 DataLoader 정의 (shuffle=True로 배치 순서 랜덤화)\n",
    "train_loader = DataLoader(\n",
    "    train_ds, batch_size=64, shuffle=True, collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "# 테스트용 DataLoader 정의 (shuffle=False로 배치 순서 고정)\n",
    "test_loader = DataLoader(\n",
    "    test_ds, batch_size=64, shuffle=False, collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fd08190f-7d6e-4847-9f1a-a9a14315605e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DistilBertModel(\n",
      "  (embeddings): Embeddings(\n",
      "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "    (position_embeddings): Embedding(512, 768)\n",
      "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (transformer): Transformer(\n",
      "    (layer): ModuleList(\n",
      "      (0-5): 6 x TransformerBlock(\n",
      "        (attention): DistilBertSdpaAttention(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (ffn): FFN(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (activation): GELUActivation()\n",
      "        )\n",
      "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "===========================================================================\n",
      "Layer (type:depth-idx)                             Param #\n",
      "===========================================================================\n",
      "DistilBertModel                                    --\n",
      "├─Embeddings: 1-1                                  --\n",
      "│    └─Embedding: 2-1                              23,440,896\n",
      "│    └─Embedding: 2-2                              393,216\n",
      "│    └─LayerNorm: 2-3                              1,536\n",
      "│    └─Dropout: 2-4                                --\n",
      "├─Transformer: 1-2                                 --\n",
      "│    └─ModuleList: 2-5                             --\n",
      "│    │    └─TransformerBlock: 3-1                  7,087,872\n",
      "│    │    └─TransformerBlock: 3-2                  7,087,872\n",
      "│    │    └─TransformerBlock: 3-3                  7,087,872\n",
      "│    │    └─TransformerBlock: 3-4                  7,087,872\n",
      "│    │    └─TransformerBlock: 3-5                  7,087,872\n",
      "│    │    └─TransformerBlock: 3-6                  7,087,872\n",
      "===========================================================================\n",
      "Total params: 66,362,880\n",
      "Trainable params: 66,362,880\n",
      "Non-trainable params: 0\n",
      "===========================================================================\n"
     ]
    }
   ],
   "source": [
    "# 모델 가져오기\n",
    "config = DistilBertConfig()\n",
    "model = DistilBertModel(config)\n",
    "print(model)\n",
    "print(summary(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a00e966d-ffaa-4da7-8f41-7b30bd5ca721",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "# 텍스트 분류 모델 정의 (DistilBERT + Linear layer)\n",
    "class TextClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # 사전학습된 DistilBERT 모델을 encoder로 사용 (pretrained transformer)\n",
    "        self.encoder = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "        # [CLS] 토큰 분류기 정의\n",
    "        self.classifier = nn.Linear(768, 4) # label의 분류가 4개이므로 출력 차원 조절\n",
    "\n",
    "    def forward(self, x):\n",
    "        # encoder에 input_ids 전달\n",
    "        x = self.encoder(x)['last_hidden_state']\n",
    "\n",
    "        # [CLS] 토큰 위치 벡터를 classification head에 전달\n",
    "        x = self.classifier(x[:, 0])\n",
    "\n",
    "        return x  # logit 출력\n",
    "\n",
    "model = TextClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f38a35aa-a2d0-4a00-9edf-ddb1ae400df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.encoder.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b355c631-cb22-493d-b875-7b65d7a6bfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e82e85c2-3ea7-4f16-a100-03add1af582f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   1 | Train Loss: 125.3775\n",
      "Epoch   2 | Train Loss: 80.8265\n",
      "Epoch   3 | Train Loss: 64.4224\n",
      "Epoch   4 | Train Loss: 58.1567\n",
      "Epoch   5 | Train Loss: 53.9230\n",
      "Epoch   6 | Train Loss: 51.5969\n",
      "Epoch   7 | Train Loss: 49.8435\n",
      "Epoch   8 | Train Loss: 48.0503\n",
      "Epoch   9 | Train Loss: 46.9408\n",
      "Epoch  10 | Train Loss: 46.2360\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import Adam\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "lr = 0.001\n",
    "model = model.to(device)\n",
    "# 일반 분류 : loss_fn으로 CrossEntropyLoss 사용\n",
    "loss_fn = nn.CrossEntropyLoss() \n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=lr)\n",
    "n_epochs = 10\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    total_loss = 0.\n",
    "    model.train()\n",
    "\n",
    "    for data in train_loader:\n",
    "        model.zero_grad()\n",
    "\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        preds = model(inputs)\n",
    "\n",
    "        loss = loss_fn(preds, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f'Epoch {epoch+1:3d} | Train Loss: {total_loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e776b70f-6475-4844-9c56-8e5e25801f7d",
   "metadata": {},
   "source": [
    "* nn.crossEntropyLoss에 label로 정수형 LongTensor를 넣어줬어야 함  \n",
    "  labels.to(device).float()에서 labels.to(device)로 수정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b42294e7-4734-409b-9d83-865a24a9c0b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========> Train acc: 0.843 | Test acc: 0.850\n"
     ]
    }
   ],
   "source": [
    "def accuracy(model, dataloader):\n",
    "    cnt = 0      # 전체 샘플 수\n",
    "    acc = 0      # 정답 개수 누적\n",
    "\n",
    "    for data in dataloader:\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        preds = model(inputs)  # (batch_size, num_classes = 4)\n",
    "        # print(preds.shape)\n",
    "        preds = torch.argmax(preds, dim=-1) # 출력 차원 조정\n",
    "\n",
    "        cnt += labels.size(0)  # 총 샘플 수 누적\n",
    "        acc += (labels == preds).sum().item()  # 예측이 맞은 수 누적\n",
    "\n",
    "    return acc / cnt  # 정확도 반환\n",
    "\n",
    "# 평가 시 gradient 계산 비활성화\n",
    "with torch.no_grad():\n",
    "    model.eval()  # 평가 모드로 전환 (계산 비활성화)\n",
    "    train_acc = accuracy(model, train_loader)\n",
    "    test_acc = accuracy(model, test_loader)\n",
    "\n",
    "    print(f\"=========> Train acc: {train_acc:.3f} | Test acc: {test_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255a39b6-2e0e-4cff-8283-16ce600d7809",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (hhplus_week3)",
   "language": "python",
   "name": "hhplus_week3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
